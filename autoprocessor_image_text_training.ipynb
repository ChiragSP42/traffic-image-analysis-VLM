{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f01eb7e0-4ca2-4f3b-9c7e-95061b09b971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T12:22:46.980890Z",
     "iopub.status.busy": "2025-09-04T12:22:46.980599Z",
     "iopub.status.idle": "2025-09-04T12:23:00.392332Z",
     "shell.execute_reply": "2025-09-04T12:23:00.391754Z",
     "shell.execute_reply.started": "2025-09-04T12:22:46.980873Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 12:22:48.462523: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756988568.477899    1732 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756988568.482785    1732 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-04 12:22:48.498381: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Any, Optional\n",
    "import logging\n",
    "import gc\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import json\n",
    "from aws_helpers import helpers\n",
    "from transformers import InternVLProcessor, AutoModelForImageTextToText\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5d872-4e2e-4282-9337-ef34a6b0b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = helpers._setup_logger(level=logging.DEBUG)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_ID = 'OpenGVLab/InternVL3-8B-hf'\n",
    "S3_BUCKET = 'signal-8-flock'\n",
    "\n",
    "def create_template(json_obj: Dict) -> str:\n",
    "    template = \"\"\n",
    "    if json_obj[\"year\"] != \"None\":\n",
    "        template += json_obj['year'] + \" \"\n",
    "    if json_obj[\"car_type\"] != \"None\":\n",
    "        template += json_obj[\"car_type\"] + \" \"\n",
    "    if json_obj[\"color\"] != \"None\":\n",
    "        template += json_obj['color'] + \" \"\n",
    "    if json_obj[\"make\"] != \"None\":\n",
    "        template += json_obj[\"make\"] + \" \"\n",
    "    if json_obj[\"model\"] != \"None\":\n",
    "        template += json_obj[\"model\"] + \" \"\n",
    "    if json_obj[\"license_plate\"] != \"None\":\n",
    "        template += f\"with license plate number {json_obj['license_plate']} \"\n",
    "    if json_obj['unique_identifiers']:\n",
    "        template += f\"has the following unique identifiers: \" + \", \".join(json_obj[\"unique_identifiers\"])\n",
    "    return template\n",
    "\n",
    "def load_image_from_s3(s3_uri: str) -> Image.Image:\n",
    "    s3_client = helpers._get_s3_client()\n",
    "    path = s3_uri[5:]\n",
    "    bucket, key = path.split(\"/\", 1)\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    img_bytes = obj[\"Body\"].read()\n",
    "    img = Image.open(BytesIO(img_bytes)).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "class ManualImageTextDataset(Dataset):\n",
    "    def __init__(self, s3_bucket: str, json_file: str):\n",
    "        self.records = []\n",
    "        s3_client = helpers._get_s3_client()\n",
    "        input_json_file = s3_client.get_object(Bucket=s3_bucket, Key=json_file)[\"Body\"].read().decode('utf-8')\n",
    "        input_json_file = json.loads(input_json_file)\n",
    "        \n",
    "        for json_obj in input_json_file['output'][:16]:\n",
    "            template = create_template(json_obj)\n",
    "            image_uri = json_obj[\"s3_uri\"]\n",
    "            self.records.append({\"image_uri\": image_uri, \"text\": template})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.records[idx]\n",
    "        \n",
    "        # Load and process image manually\n",
    "        image = load_image_from_s3(s3_uri=record[\"image_uri\"])\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"conversation\": record[\"text\"]\n",
    "        }\n",
    "\n",
    "class ManualCollator:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        images = [b['image'] for b in batch]\n",
    "        texts = [b['conversation'] for b in batch]\n",
    "        \n",
    "        processed = processor(\n",
    "            images=images,\n",
    "            text=texts,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        logger.debug(type(processed))\n",
    "        \n",
    "        return {\n",
    "            \"pixel_values\": processed['pixel_values'],\n",
    "            \"input_ids\": processed['input_ids'],\n",
    "            \"attention_mask\": processed['attention_mask'],\n",
    "            \"labels\": processed['labels']\n",
    "        }\n",
    "\n",
    "# Manual forward pass function\n",
    "def manual_forward_pass(model, batch):\n",
    "    \"\"\"\n",
    "    Manually handle model forward pass and loss computation\n",
    "    \"\"\"\n",
    "    pixel_values = batch['pixel_values'].to(DEVICE)\n",
    "    input_ids = batch['input_ids'].to(DEVICE)\n",
    "    attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "    labels = batch['labels'].to(DEVICE)\n",
    "    \n",
    "    # Forward pass - note: this might need adjustment based on actual model API\n",
    "    # InternVL3-hf should accept these arguments\n",
    "    outputs = model(\n",
    "        pixel_values=pixel_values,\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        labels=labels  # Model should compute loss automatically\n",
    "    )\n",
    "    \n",
    "    return outputs.loss if hasattr(outputs, 'loss') else None\n",
    "\n",
    "def main():\n",
    "    # Load tokenizer only (no processor)\n",
    "    processor = InternVLProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    \n",
    "    # Ensure pad token exists\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForImageTextToText.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    model.train()\n",
    "    \n",
    "    logger.info(\"Creating dataset\")\n",
    "    dataset = ManualImageTextDataset(json_file='created_data.json', s3_bucket=S3_BUCKET)\n",
    "    logger.info(f\"Created dataset with {len(dataset)} samples\")\n",
    "    \n",
    "    logger.info(\"Creating collator\")\n",
    "    collator = ManualCollator(tokenizer, max_length=256)\n",
    "    \n",
    "    logger.info(\"Creating dataloader\")\n",
    "    dataloader = DataLoader(dataset, batch_size=8, collate_fn=collator, shuffle=True)\n",
    "    \n",
    "    # Test single batch first\n",
    "    # logger.info(\"Testing single batch...\")\n",
    "    # try:\n",
    "    #     sample_batch = next(iter(dataloader))\n",
    "    #     logger.info(\"✅ Batch creation successful!\")\n",
    "    #     logger.info(f\"Batch keys: {sample_batch.keys()}\")\n",
    "    #     logger.info(f\"Pixel values shape: {sample_batch['pixel_values'].shape}\")\n",
    "    #     logger.info(f\"Input IDs shape: {sample_batch['input_ids'].shape}\")\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     logger.error(f\"❌ Error: {e}\")\n",
    "    \n",
    "    # Full training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    logger.info(\"Starting training...\")\n",
    "    for epoch in range(10):  # Reduced for testing\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            try:\n",
    "                loss = manual_forward_pass(model, batch)\n",
    "                \n",
    "                if loss is not None:\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    logger.info(f\"✅ Step {step}, Loss: {loss.item():.4f}\")\n",
    "                else:\n",
    "                    logger.warning(f\"⚠️ Step {step}, No loss returned\")\n",
    "                \n",
    "                if step >= 2:  # Test just a few steps\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"❌ Step {step} failed: {e}\")\n",
    "                break\n",
    "        \n",
    "        break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
